{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liable-label",
   "metadata": {},
   "source": [
    "# **Advanced Feature Engineering in BQML**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-enough",
   "metadata": {},
   "source": [
    "**Learning Objectives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-patch",
   "metadata": {},
   "source": [
    "1. Evaluate the model\n",
    "2. Extract temporal features, feature cross temporal features\n",
    "3. Apply `ML.FEATURE_CROSS` to categorical features\n",
    "4. Create a Euclidian feature column, feature cross coordinate features\n",
    "5. Apply the `BUCKETIZE` function, `TRANSFORM` clause, L2 Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-terrace",
   "metadata": {},
   "source": [
    "## **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-dominant",
   "metadata": {},
   "source": [
    "In this lab, we utilise feature engineering to improve the prediction of the fare amount for a taxi ride in New York City. We will use BigQuery ML to build a taxifare prediction model, using feature engineering to improve and create a final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-secondary",
   "metadata": {},
   "source": [
    "In this notebook, we perform a feature cross using BigQuery's `ML.FEATURE_CROSS`, derive coordinate features, feature cross coordinate features, clean up the code, apply the `BUCKETIZE` function, the `TRANSFORM` clause, L2 Regularisation, and evaluate model performance throughout the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-stuff",
   "metadata": {},
   "source": [
    "## **Set up environment variables and load necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Google Cloud BigQuery\n",
    "!pip install --user google-cloud-bigquery=1.25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "export PROJECT=$(gcloud config list project --format \"value(core.project)\")\n",
    "echo \"Your current GCP Project Name is \"$PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-limit",
   "metadata": {},
   "source": [
    "## **The source data set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-manner",
   "metadata": {},
   "source": [
    "Our data set is hosted in BigQuery. The taxi fare data is a publically available data set, meaning anyone with a GCP account has access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-administration",
   "metadata": {},
   "source": [
    "The Taxi Fare data set is relatively large at 55 million training rows, but simple to understand, with only 6 features. The `fare_amount` is the target, the continuous value we'll train a model to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-evans",
   "metadata": {},
   "source": [
    "## **Create a BigQuery data set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-cooling",
   "metadata": {},
   "source": [
    "A BigQuery data set is a container for tables, views, and models built with BigQuery ML. Let's create one called **feat_eng**. Weel do the same for a GCS bucket for our project too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create a BigQuery data set for feat_eng if it doesn't exist\n",
    "datasetexists=$(bq ls -d | grep -w feat_eng)\n",
    "\n",
    "if [ -n \"$datasetexists\"]; then\n",
    "    echo -e \"BigQuery dataset already exists, let's not recreate it\"\n",
    "\n",
    "else\n",
    "    echo \"Creating BigQuery dataset titled: feat_eng\"\n",
    "    \n",
    "    bq --location=US mk --dataset \\\n",
    "        --description \"Taxi Fare\" \\\n",
    "        $PROJECT:feat_eng\n",
    "    echo \"\\nHere are your current datasets:\"\n",
    "    bq ls\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-merchant",
   "metadata": {},
   "source": [
    "## **Creating the training table**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-animation",
   "metadata": {},
   "source": [
    "Since there is already a publicly available data set, we can simply create the training data table using this raw input data. Note the `WHERE` clause in the below query: This clause allows us to TRAIN a portion of the data (e.g. one hundred thousand rows versus one million rows), which keeps our query costs down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Creating the table in our data set\n",
    "CREATE OR REPLACE TABLE\n",
    "    feat_eng.feateng_training_data AS\n",
    "SELECT\n",
    "    (tolls_amount + fare_amount) AS fare_amount,\n",
    "    passenger_count * 1.0 AS passengers,\n",
    "    pickup_datetime,\n",
    "    pickup_longitude AS pickuplon,\n",
    "    pickup_latitude AS pickuplat,\n",
    "    dropoff_longitude AS dropofflon,\n",
    "    dropoff_latitude AS dropofflat\n",
    "FROM\n",
    "    `nyc-tlc.yellow.trips`\n",
    "WHERE\n",
    "    MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING))), 10000) = 1\n",
    "    AND fare_amount >= 2.5\n",
    "    AND passenger_count > 0\n",
    "    AND pickup_longitude > -78\n",
    "    AND pickup_longitude < -70\n",
    "    AND dropoff_longitude > -78\n",
    "    AND dropoff_longitude < -70\n",
    "    AND pickup_latitude > 37\n",
    "    AND pickup_latitude < 45\n",
    "    AND dropoff_latitude > 37\n",
    "    AND dropoff_latitude < 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-onion",
   "metadata": {},
   "source": [
    "## **Verify table creation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-brass",
   "metadata": {},
   "source": [
    "Verify that you created the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# LIMIT 0 is a free query; this allows us to check that the table exists\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    feat_eng.feateng_training_data\n",
    "LIMIT\n",
    "    0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-worthy",
   "metadata": {},
   "source": [
    "## **Baseline Model: Create the baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-exhaust",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-amino",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-clearing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-monday",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
