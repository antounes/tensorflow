{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "critical-failing",
   "metadata": {},
   "source": [
    "# **Advanced Feature Engineering in BQML**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-commonwealth",
   "metadata": {},
   "source": [
    "**Learning Objectives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-segment",
   "metadata": {},
   "source": [
    "1. Evaluate the model\n",
    "2. Extract temporal features, feature cross temporal features\n",
    "3. Apply `ML.FEATURE_CROSS` to categorical features\n",
    "4. Create a Euclidian feature column, feature cross coordinate features\n",
    "5. Apply the `BUCKETIZE` function, `TRANSFORM` clause, L2 Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-combination",
   "metadata": {},
   "source": [
    "## **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-playback",
   "metadata": {},
   "source": [
    "In this lab, we utilise feature engineering to improve the prediction of the fare amount for a taxi ride in New York City. We will use BigQuery ML to build a taxifare prediction model, using feature engineering to improve and create a final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-portrait",
   "metadata": {},
   "source": [
    "In this notebook, we perform a feature cross using BigQuery's `ML.FEATURE_CROSS`, derive coordinate features, feature cross coordinate features, clean up the code, apply the `BUCKETIZE` function, the `TRANSFORM` clause, L2 Regularisation, and evaluate model performance throughout the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-shopping",
   "metadata": {},
   "source": [
    "## **Set up environment variables and load necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Google Cloud BigQuery\n",
    "!pip install --user google-cloud-bigquery=1.25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "export PROJECT=$(gcloud config list project --format \"value(core.project)\")\n",
    "echo \"Your current GCP Project Name is \"$PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-tower",
   "metadata": {},
   "source": [
    "## **The source data set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-married",
   "metadata": {},
   "source": [
    "Our data set is hosted in BigQuery. The taxi fare data is a publically available data set, meaning anyone with a GCP account has access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-department",
   "metadata": {},
   "source": [
    "The Taxi Fare data set is relatively large at 55 million training rows, but simple to understand, with only 6 features. The `fare_amount` is the target, the continuous value we'll train a model to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-array",
   "metadata": {},
   "source": [
    "## **Create a BigQuery data set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-panic",
   "metadata": {},
   "source": [
    "A BigQuery data set is a container for tables, views, and models built with BigQuery ML. Let's create one called **feat_eng**. Weel do the same for a GCS bucket for our project too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create a BigQuery data set for feat_eng if it doesn't exist\n",
    "datasetexists=$(bq ls -d | grep -w feat_eng)\n",
    "\n",
    "if [ -n \"$datasetexists\"]; then\n",
    "    echo -e \"BigQuery dataset already exists, let's not recreate it\"\n",
    "\n",
    "else\n",
    "    echo \"Creating BigQuery dataset titled: feat_eng\"\n",
    "    \n",
    "    bq --location=US mk --dataset \\\n",
    "        --description \"Taxi Fare\" \\\n",
    "        $PROJECT:feat_eng\n",
    "    echo \"\\nHere are your current datasets:\"\n",
    "    bq ls\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-relay",
   "metadata": {},
   "source": [
    "## **Creating the training table**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-brief",
   "metadata": {},
   "source": [
    "Since there is already a publicly available data set, we can simply create the training data table using this raw input data. Note the `WHERE` clause in the below query: This clause allows us to TRAIN a portion of the data (e.g. one hundred thousand rows versus one million rows), which keeps our query costs down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Creating the table in our data set\n",
    "CREATE OR REPLACE TABLE\n",
    "    feat_eng.feateng_training_data AS\n",
    "SELECT\n",
    "    (tolls_amount + fare_amount) AS fare_amount,\n",
    "    passenger_count * 1.0 AS passengers,\n",
    "    pickup_datetime,\n",
    "    pickup_longitude AS pickuplon,\n",
    "    pickup_latitude AS pickuplat,\n",
    "    dropoff_longitude AS dropofflon,\n",
    "    dropoff_latitude AS dropofflat\n",
    "FROM\n",
    "    `nyc-tlc.yellow.trips`\n",
    "WHERE\n",
    "    MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING))), 10000) = 1\n",
    "    AND fare_amount >= 2.5\n",
    "    AND passenger_count > 0\n",
    "    AND pickup_longitude > -78\n",
    "    AND pickup_longitude < -70\n",
    "    AND dropoff_longitude > -78\n",
    "    AND dropoff_longitude < -70\n",
    "    AND pickup_latitude > 37\n",
    "    AND pickup_latitude < 45\n",
    "    AND dropoff_latitude > 37\n",
    "    AND dropoff_latitude < 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-fortune",
   "metadata": {},
   "source": [
    "## **Verify table creation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-seven",
   "metadata": {},
   "source": [
    "Verify that you created the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# LIMIT 0 is a free query; this allows us to check that the table exists\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    feat_eng.feateng_training_data\n",
    "LIMIT\n",
    "    0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-lemon",
   "metadata": {},
   "source": [
    "## **Baseline Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-inspection",
   "metadata": {},
   "source": [
    "### **Create the baseline model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-hughes",
   "metadata": {},
   "source": [
    "Next, you create a linear regression basline model with no feature engineering. Recall that a model in BigQuery ML represents what an ML system has learned from the training data. A baseline model is a solution to a problem without applying any ML techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-wilson",
   "metadata": {},
   "source": [
    "When creating a BQML model, you must specify the model type (in our case linear regression) and the input label (`fare_amount`). Note also that we are using the training data table as the data source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-prospect",
   "metadata": {},
   "source": [
    "Now we create the SQL statement to create the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%biquery\n",
    "\n",
    "# Creating the baseline model\n",
    "CREATE OR REPLACE MODEL\n",
    "    feat_eng.baseline_model OPTIONS(model_type=\"linear_reg\",\n",
    "                                    input_label_cols=[\"fare_amount\"])\n",
    "    AS\n",
    "SELECT\n",
    "    fare_amount,\n",
    "    passengers,\n",
    "    pickup_datetime,\n",
    "    pickuplon,\n",
    "    pikcuplat,\n",
    "    dropofflon,\n",
    "    dropofflat\n",
    "FROM\n",
    "    feat_eng.feateng_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-savings",
   "metadata": {},
   "source": [
    "### **Evaluate the baseline model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-house",
   "metadata": {},
   "source": [
    "Note that BigQuery automatically split the data we gave it, and trained on only a part of the data set and used the rest for evaluation. After creating your model, you evaluate the performance of the regressor using the `ML.EVALUATE` function. The `ML.EVALUATE` function evaluates the predicted values against the actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-simon",
   "metadata": {},
   "source": [
    "Review the learning and eval statistics for the `baseline_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Eval statistics on the held out data.\n",
    "SELECT\n",
    "    *,\n",
    "    SQRT(loss) AS rmse\n",
    "FROM\n",
    "    ML.TRAINING_INFO(MODEL feat_eng.baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-calgary",
   "metadata": {},
   "source": [
    "**NOTE:** Because you performed a linear regression, the results include the following columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-alabama",
   "metadata": {},
   "source": [
    "- `mean_absolute_error`\n",
    "- `mean_squared_error`\n",
    "- `mean_squared_log_error`\n",
    "- `median_absolute_error`\n",
    "- `r2_score`\n",
    "- `explained_variance`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-lloyd",
   "metadata": {},
   "source": [
    "**Mean squared error (MSE)** $-$ Measures the difference between the values our model predicted using the test set and the actual values. You can also think of it as the distance between your regression (best fit) line and the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-apparel",
   "metadata": {},
   "source": [
    "**Root mean squared error (RMSE)** $-$ The primary evaluation metric for this ML problem is the root mean squared error. RMSE measures the difference between the predictions of a model, and the observed values. A large RMSE is equivalent to a large average error, so smaller values of RMSE are better. One nice property of RMSE is that the error is given in the units being measured, so you can tell very directly how incorrect the model might be on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-degree",
   "metadata": {},
   "source": [
    "**R2**: An important metric in the evaluation results in the R2 score. The R2 score is a statistical measure that determines if the linear regression predictions approxumate the actual data. $0$ indicates that the model explains none of the variability of the response data around the mean. $1$ indicates that the model explains all the variability of the response data around the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-charter",
   "metadata": {},
   "source": [
    "Next, we write a SQL query to take the `SQRT()` of the mean squared error as your loss metric for evaluation for the `benchmark_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    SQRT(mean_squared_error) AS rmse\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-england",
   "metadata": {},
   "source": [
    "## **Model 1 $-$ EXTRACT `dayofweek` from the `pickup_datetime` feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-retirement",
   "metadata": {},
   "source": [
    "- As you recall, `dayofweek` is an `enum` representing the 7 days of the week. This factory allows the `enum` to be obtained from the `int` value. The `int` value follows the ISO-8601 standard, from `1` (Monday) to `7` (Sunday).\n",
    "- If you were to extract the `dayofweek` from `pickup_datetime` using BigQuery SQL, the datatype returned would be integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-commonwealth",
   "metadata": {},
   "source": [
    "Next, we create a model titled `model_1` from the baseline model and extract out the `DayOfWeek`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Creating the model from baseline model and extract the Days of Week\n",
    "CREATE OR REPLACE MODEL\n",
    "    feat_eng.model_1 OPTIONS (model_type=\"linear_reg\",\n",
    "                              input_label_cols=[\"fare_amount\"]) AS\n",
    "SELECT\n",
    "    fare_amount,\n",
    "    passengers,\n",
    "    pickup_datetime,\n",
    "    EXTRACT(DAYOFWEEK FROM pickup_datetime) AS dayofweek,\n",
    "    pickuplon,\n",
    "    pickuplat,\n",
    "    dropofflon,\n",
    "    dropofflat\n",
    "FROM\n",
    "    feat_eng.feateng_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-monster",
   "metadata": {},
   "source": [
    "Next, two distinct SQL statements show the TRAINING and EVALUATION metrics of `model_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.TRAINING_INFO` function which allows you to see information about the training iterations of a model\n",
    "SELECT\n",
    "    *,\n",
    "    SQRT(loss) AS rmse\n",
    "FROM\n",
    "    ML.TRAINING_INFO(MODEL feat_eng.model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics.\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "%% bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    SQRT(mean_squared_error) AS rmse\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-navigation",
   "metadata": {},
   "source": [
    "## **Model 2 $-$ EXTRACT `hourofday` from the `pickup_datetime` feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-clarity",
   "metadata": {},
   "source": [
    "As you recall, `pickup_datetime` is stored as a TIMESTAMP, where the Timestamp format is retrieved in the standard output format $-$ year-month-day hour:minute:second. `hourofday` returns the integer number representing the hour number of the given date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-alexander",
   "metadata": {},
   "source": [
    "`hourofday` is best thought of as a discrete ordinal variable (and not a categorical feature), as the hours can be ranked (e.g. there is a natural ordering of the values). `hourofday` has an added characteristic of being cyclic, since 12am follows 11pm and precedes 1am."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-nevada",
   "metadata": {},
   "source": [
    "Next, we create a model titled `model_2` and EXTRACT the `hourofday` from the `pickup_datetime` feature to improve our model's rmse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Creating the model from baseline model and extract the hours of day\n",
    "CREATE OR REPLACE MODEL\n",
    "    feat_eng.model_2 OPTIONS (model_type=\"linear_reg\",\n",
    "                              input_label_cols=[\"fare_amount\"]) AS\n",
    "SELECT\n",
    "    fare_amount,\n",
    "    passengers,\n",
    "    EXTRACT(DAYOFWEEK FROM pickup_datetime) AS dayofweek,\n",
    "    EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
    "    pickuplon,\n",
    "    pickuplat,\n",
    "    dropofflon,\n",
    "    dropofflat\n",
    "FROM\n",
    "    `feat_eng.feateng_training_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    SQRT(mean_squared_error) AS rmse\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-method",
   "metadata": {},
   "source": [
    "## **Model 3 $-$ Feature cross `dayofweek` and `hourofday` using `CONCAT`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-engagement",
   "metadata": {},
   "source": [
    "First, let's allow the model to learn traffic patterns by creating a new feature that combines the time of day and day of week. This is called a *feature cross*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-excuse",
   "metadata": {},
   "source": [
    "Note: BQML by default assumes that numbers are numeric features, and strings are categorical features. We need to convert both the `dayofweek` and `hourofday` features to strings because the model (Neural Network) will automatically treat any integer as a numerical value rather than a categorical value. Thus, if not cast as string, the `dayofweek` feature will be interpreted as numeric values (e.g. $1, 2, 3, 4, 5, 6, 7$) and `hourofday` will also be interpreted as numeric values (e.g. the day begins at midnight, `00:00`, and the last minute of the day begins at `23:59` and ends at `24:00`). As such, there is no way to distinguish the *feature cross* of `hourofday` and `dayofweek` *numerically*. Casting the `dayofweek` and `hourofday` as strings ensures that each element will be treated like a label and will get its own coefficient associated with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-montana",
   "metadata": {},
   "source": [
    "Create the SQL statement to feature cross the `dayofweek` and `hourofday` using the CONCAT function. Name the model `model_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Using `CONCAT` function to feature cross the `dayofweek` and `hourofday`\n",
    "CREATE OR REPLACE MODEL\n",
    "    feat_eng.model_3 OPTIONS(model_type=\"linear_reg\",\n",
    "                             input_label_cols=[\"fare_amount\"]) AS\n",
    "SELECT\n",
    "    fare_amount,\n",
    "    passengers,\n",
    "    CONCAT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING), \n",
    "           CAST (EXTRACT(HOUR FROM pickup_datetime) AS STRING)) AS hourofday,\n",
    "    pickuplon,\n",
    "    pickuplat,\n",
    "    dropofflon,\n",
    "    dropofflat\n",
    "FROM\n",
    "    `feat_eng.feateng_training_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    SQRT(mean_squared_error) AS rmse\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-sending",
   "metadata": {},
   "source": [
    "## **Model 4 $-$ Apply the `ML.FEATURE_CROSS` clause to categorical features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-container",
   "metadata": {},
   "source": [
    "BigQuery ML now has `ML.FEATURE_CROSS`, a pre-processing clause that performs a feature cross."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-specialist",
   "metadata": {},
   "source": [
    "- `ML.FEATURE_CROSS` generates a `STRUCT` feature with all combinations of crossed categorical features, except for 1-degree items (the original features) and self-crossing items.\n",
    "- Syntax: `ML.FEATURE_CROSS(STRUCT(features), degree)\n",
    "- `features`: Categorical features to be crossed separated by `,`. The maximum number of input features is 10. An unnamed feature is not allowed in features. Duplicates are not allowed in features\n",
    "- `degree` (optional): The highest degree of all combinations. Degree should be in the rage of `[1, 4]`. Default to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-religious",
   "metadata": {},
   "source": [
    "Output: The function outputs a STRUCT of all combinations except for 1-degree items and self-crossing items, with field names as concatenation of original feature names and values as the concatenation of the column string values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-romantic",
   "metadata": {},
   "source": [
    "Here, we examine the components of `ML.FEATURE_CROSS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Using the `ML.FEATURE_CROSS` clause\n",
    "CREATE OR REPLACE MODEL \n",
    "    feat_eng.model_4 OPTIONS(model_type=\"linear_reg\",\n",
    "                             input_label_cols=[\"fare_amount\"]) AS\n",
    "SELECT\n",
    "    fare_amount,\n",
    "    passengers,\n",
    "    ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING) AS dayofweek,\n",
    "                            CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
    "    pickuplon,\n",
    "    pickuplat,\n",
    "    dropofflon,\n",
    "    dropofflat\n",
    "\n",
    "FROM `feat_eng.feateng_training_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-thumbnail",
   "metadata": {},
   "source": [
    "Next, two distinct SQL statements show the TRAINING and EVALUATION metrics of `model_4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    SQRT(mean_squared_error) AS rmse\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.model_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-softball",
   "metadata": {},
   "source": [
    "## **Sliding down the slope towards a loss minimum (reduced taxi fare)!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-affect",
   "metadata": {},
   "source": [
    "- Our fourth model gives us an RMSE of 9.65 for estimating fares. Recall our heuristic baseline was 8.29. This may be the result of feature cross. Let's apply more feature engineering techniques to see if we can't get this loss metric lower!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-small",
   "metadata": {},
   "source": [
    "## **Model 5 $-$ Feature cross coordinate features to create a Euclidean feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-madonna",
   "metadata": {},
   "source": [
    "Pickup coordinate:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-minority",
   "metadata": {},
   "source": [
    "- `pickup_longitude` AS `pickuplon`\n",
    "- `pickup_latitude` AS `pickuplat`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-analyst",
   "metadata": {},
   "source": [
    "Dropoff coordinate:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-longitude",
   "metadata": {},
   "source": [
    "- `droppoff_longitude` AS `dropofflon`\n",
    "- `dropoff_latitude` AS `dropofflat`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-letters",
   "metadata": {},
   "source": [
    "### **Coordinate Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-cricket",
   "metadata": {},
   "source": [
    "- The pick-up and drop-off longitude and latitude data are crucial to predicting the fare amount as fare amounts in NYC taxis are largely determined by the distance traveled. As such, we need to teach the model the Euclidean distance bewteen the pick-up and drop-off points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-artist",
   "metadata": {},
   "source": [
    "- Recall that latitude and longitude allow us to specify any location on Earth using a set of coordinates. In our training data set, we restricted our data points to only pick ups and drop offs within NYC. New York City has an appropriate longitude range of $-74.05$ to $-73.75$ and a latitude range of $40.63$ to $40.85$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-hands",
   "metadata": {},
   "source": [
    "- The data set contains information regarding the pick up and drop off coordinates. However, there is no information regarding the distance between the pick up and drop off points. Therefore, we create a new feature that calculates the distance between each pair of pickup and drop off points. We can do this using the Euclidean Distance, which is the straight-line distance between any two coordinate points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-sweet",
   "metadata": {},
   "source": [
    "- We need to convert those coordinates into a single column of a spatial data type. We will use the `ST_Distance` and the `ST_GeogPoint` functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-observer",
   "metadata": {},
   "source": [
    "- `ST_Distance(geography_1, geography_2)`: Returns the shortest distance in meters between two non-empy `GEOGRAPHY`s (e.g. between two spatial objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-details",
   "metadata": {},
   "source": [
    "- `ST_GeogPoint(longitude, latitude)`: Creates a `GEOGRAPHY` with a single point. `ST_GEOPOINT` creates a point from the specified `FLOAT64` `latitude` and `longitude` parameters and returns that point in a `GEOGRAPHY` value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-clothing",
   "metadata": {},
   "source": [
    "Next we convert the feature coordinates into a single column of a spatial data type. Use the `ST_Distance` and the `ST_GeogPoint` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Convert the feature coordinates into a single column of a `spatial` data type\n",
    "CREATE OR REPLACE MODEL\n",
    "    feat_eng.model_5 OPTIONS(model_type=\"linear_reg\",\n",
    "                             input_label_cols=[\"fare_amount\"]) AS\n",
    "SELECT\n",
    "    fare_amount,\n",
    "    passengers,\n",
    "    ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING) AS dayofweek,\n",
    "                            CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
    "    ST_Distance(ST_GeogPoint(pikcuplon, pickuplat), ST_GeogPoint(dropofflon, dropofflat)) AS euclidean\n",
    "FROM\n",
    "    `feat_eng.feateng_training_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-buyer",
   "metadata": {},
   "source": [
    "Next, two distinct SQL statements show metrics for `model_5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.model_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    SQRT(mean_squared_error) AS rmse\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.model_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-navigator",
   "metadata": {},
   "source": [
    "## **Model 6 $-$ Feature cross pick-up and drop-off locations features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-posting",
   "metadata": {},
   "source": [
    "In this section, we feature cross the pick-up and drop-off locations so that the model can learn pick-up-drop-off pairs that will require tolls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-plenty",
   "metadata": {},
   "source": [
    "This step takes the geographic point corresponding to the pickup point and grids to a $0.1$-degree-latitude/longitude grid (approximately $8$ km $\\times$ $11$ km in New York $-$ we should experiment with finer grid resolutions as well). Then, it concatenates the pickup and dropoff grid points to learn *corrections* beyond the Euclidean distance associated with pairs of pickup and dropoff locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-advice",
   "metadata": {},
   "source": [
    "Because the lat and lon by themselves don't have meaning, but only in conjunction, it may be useful to treat the  fields as a pair instead of just using them as numeric values. However, lat and lon are continuous numbers, so we have to discretise them first. That's what `SnapToGrid` does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-mauritius",
   "metadata": {},
   "source": [
    "- `ST_SnapToGrid(geography_expression, grid_size)`: Returns the input `GEOGRAPHY`, where each vertex has been snapped to a longitude/latitude grid. The grid size is determined by the `grid_size` parameter which is given in degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-abuse",
   "metadata": {},
   "source": [
    "**REMINDER**: The `ST_GeogPoint` creates a `GEOGRAPHY` with a single point. `ST_GeogPoint` creates a point from the specified `FLOAT64` longitude and latitude parameters and returns that point in a `GEOGRAPHY` value. The `ST_Distance` function returns the minimum distance beteween two spatial objects. It also returns meters for geographies and SRID units for geometrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use feature cross for the pick-up and drop-off locations features\n",
    "CREATE OR REPLACE MODEL\n",
    "    feat_eng.model_6 OPTIONS(model_type=\"linear_reg\",\n",
    "                             input_label_cols=[\"fare_amount\"]) AS\n",
    "SELECT\n",
    "    fare_amount,\n",
    "    passengers,\n",
    "    ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING) AS dayofweek,\n",
    "                            CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
    "    ST_Distance(ST_GeogPoint(pickuplon, pickuplat), ST_GeogPoint(dropofflon, dropofflat)) AS euclidean,\n",
    "    CONCAT(ST_AsText(ST_SnapToGrid(ST_GeogPoint(pickuplon, pickuplat), 0.01)),\n",
    "           ST_AsText(ST_SnapToGrid(ST_GeogPoint(dropofflon, dropofflat), 0.01))) AS pickup_and_dropoff\n",
    "FROM\n",
    "    `feat_eng.feateng_training_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-stand",
   "metadata": {},
   "source": [
    "Next, we evaluate `model_6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.model_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    SQRT(mean_squared_error) AS rmse\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.model_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-siemens",
   "metadata": {},
   "source": [
    "## **BQML's Pre-processing functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-brooks",
   "metadata": {},
   "source": [
    "Here are some of the preprocessing functions in BigQuery ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-carrier",
   "metadata": {},
   "source": [
    "- `ML.FEATURE_CROSS(STRUCT(features))` does a feature cross of all the combinations\n",
    "- `ML.POLYNOMIAL_EXPAND(STRUCT(features), degree)` creates $x$, $x^2$, $x^3$, etc.\n",
    "- `ML.BUCKETIZE(feature, split_points)` where `split_points` is an array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-spice",
   "metadata": {},
   "source": [
    "## **Model 7 $-$ Apply the `BUCKETIZE` function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-finland",
   "metadata": {},
   "source": [
    "`BUCKETIZE` is a pre-processing function that creates *buckets* (e.g. bins) $-$ e.g. it bucketises a continuous numerical feature into a string feature with bucket names as the value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-kernel",
   "metadata": {},
   "source": [
    "- `ML.BUCKETIZE(feautre, split_points)`\n",
    "- `feature`: A numerical column\n",
    "- `split_points`: Array of numerical points to split the continuous values in feature into buckets. With $n$ split points (`s1`, `s2`,..., `sn`), there will be $n+1$ buckets generated.\n",
    "- output: The function outputs a `STRING` for each row, which is the bucket name\n",
    "- Currently, our model uses the `ST_GeogPoint` function to derive the pickup and dropoff feature. In this lab, we use the `BUCKETIZE` function to create the pickup and dropoff feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-florence",
   "metadata": {},
   "source": [
    "Next, apply the `BUCKETIZE` function to `model_7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `BUCKETIZE` function\n",
    "CREATE OR REPLACE MODEL\n",
    "    feat_eng.model_7 OPTIONS(model_type=\"linear_reg\",\n",
    "                             input_label_cols=[\"fare_amount\"]) AS\n",
    "SELECT\n",
    "    fare_amount,\n",
    "    passengers,\n",
    "    ST_Distance(ST_GeogPoint(pickuplon, pickuplat), ST_GeogPoint(dropofflon, dropofflat)) AS euclidean,\n",
    "    ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING) AS dayofweek,\n",
    "                            CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
    "    CONCAT(ML.BUCKETIZE(pickuplon, GENERATE_ARRAY(-78, -70, 0.01)),\n",
    "           ML.BUCKETIZE(pickuplat, GENERATE_ARRAY(37, 45, 0.01)),\n",
    "           ML.BUCKETIZE(dropofflon, GENERATE_ARRAY(-78, -70, 0.01)),\n",
    "           ML.BUCKETIZE(dropofflat, GENERATE_ARRAY(37, 45, 0.01))) AS pickup_and_dropoff\n",
    "FROM\n",
    "    `feat_eng.feateng_training_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-elephant",
   "metadata": {},
   "source": [
    "Next, we evaluate `model_7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.TRAINING_INFO` function which allows you to see information about the training iterations of a model\n",
    "SELECT\n",
    "    *,\n",
    "    SQRT(loss) AS rmse\n",
    "FROM\n",
    "    ML.TRAINING_INFO(MODEL feat_eng.model_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.model_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    SQRT(mean_squared_error) AS rmse\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.model_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-eligibility",
   "metadata": {},
   "source": [
    "## **Final Model: Apply the `TRANSFORM` clause and L2 Regularisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-society",
   "metadata": {},
   "source": [
    "Before we perform our prediction, we should encapsulate the entire feature set in a `TRANSFORM` clause. BigQuery ML now supports defining data transformations during model creation, which will be automatically applied during prediction and evaluation. This is done through the `TRANSFORM` clause in the existing `CREATE MODEL` statement. By using the `TRANSFORM` clause, user specified transforms during training will be automatically applied during model serving (prediction, evaluation, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-pickup",
   "metadata": {},
   "source": [
    "In our case, we are using the `TRANSFORM` clause to separate out the raw input data from the *transformed* features. The input columns of the `TRANSFORM` clause are the `query_expr` (`AS SELECT` part). The output columns of the `TRANSFORM` from `select_list` are used in training. These transformed columns are post-processed with standardisation for numerics and one-hot encoding for categorical variables by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-keeping",
   "metadata": {},
   "source": [
    "The advantage of encapsulating features in the `TRANSFORM` clause is the client code doing the `PREDICT` doesn't chage, e.g. our model improvement is transparent to client code. Note that the `TRANSFORM` clause `MUST` be placed after the `CREATE` statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-doubt",
   "metadata": {},
   "source": [
    "### **L2 Regularisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-diana",
   "metadata": {},
   "source": [
    "Sometimes, the training RMSE is quite reasonable, but the evaluation RMSE illustrates more error. Given the severity of the delta between the `EVALUATION RMSE` and the `TRAINING RMSE`, it may be an indication of *overfitting*. When we do feature crosses, we run into the risk of overfitting (for example, when a particular day-hour combo doesn't have enough taxi rides)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-address",
   "metadata": {},
   "source": [
    "Overfitting is a phenomenon that occurs when an ML model is tailored to a particular data set and is unable to generalise to other data sets. This usually happens in complex models, like deep neural networks. Regularisation is a process of introducing additional information in order to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-election",
   "metadata": {},
   "source": [
    "Therefore, we will apply L2 regularisation to the final model. As a reminder, a regression model that uses the **L1 regularisation** technique is called **Lasso regression** while a regression model that uses the **L2 regularisation** technique is called **Ridge regression**. The key difference between these two is the penalty term. Lasso shrinks the less important feature's coefficient to $0$, thus removing some features altogether. Ridge regression adds *squared magnitude* of coefficient as a penalty term to the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-norfolk",
   "metadata": {},
   "source": [
    "In other words, **L1 limits the size of the coefficients**. L1 can yield sparse models (i.e. models with few coefficients). Some coefficients can become $0$ and eliminated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-booth",
   "metadata": {},
   "source": [
    "**L2 will not yield sparse models** and all coefficients are shrunk by the same factor (none are eliminated)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-queens",
   "metadata": {},
   "source": [
    "The regularisation terms are *constraints* by which an optimisation algorithm must *adhere to* when minimising the loss function, apart from having to minimise the error between the true $y$ and the predicted $\\hat{y}$. This in turn reduces model complexity, making our model simpler. A simpler model can reduce the chances of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-clause",
   "metadata": {},
   "source": [
    "Apply the `TRANSFORM` clause and L2 regularisation to the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use the `TRANSFORM` clause\n",
    "CREATE OR REPLACE MODEL\n",
    "    feat_eng.final_model\n",
    "    TRANSFORM(fare_amount,\n",
    "              ST_Distance(ST_GeogPoint(pickuplon, pickuplat), ST_GeogPoint(dropofflon, dropofflat)) AS euclidean,\n",
    "              ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING) AS dayofweek,\n",
    "                                      CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
    "              CONCAT(ML.BUCKETIZE(pickuplon, GENERATE_ARRAY(-78, -70, 0.01)),\n",
    "                     ML.BUCKETIZE(pickuplat, GENERATE_ARRAY(37, 45, 0.01)),\n",
    "                     ML.BUCKETIZE(dropofflon, GENERATE_ARRAY(-78, -70, 0.01)),\n",
    "                     ML.BUCKETIZE(dropofflat, GENERATE_ARRAY(37, 45, 0.01))) AS pickup_and_dropoff) \n",
    "    OPTIONS(input_label_cols=[\"fare_amount\"],\n",
    "            model_type=\"linear_reg\",\n",
    "            l2_reg=0.1) AS\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    feat_eng.feateng_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-queen",
   "metadata": {},
   "source": [
    "Next, we evaluate the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.TRAINING_INFO` function which allows you to see information about the training iterations of a model\n",
    "SELECT\n",
    "    *,\n",
    "    SQRT(loss) AS rmse\n",
    "FROM\n",
    "    ML.TRAINING_INFO(MODEL feat_eng.final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.EVALUATE` function to evaluate model metrics\n",
    "SELECT\n",
    "    SQRT(mean_squared_error) AS rmse\n",
    "FROM\n",
    "    ML.EVALUATE(MODEL feat_eng.final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-correspondence",
   "metadata": {},
   "source": [
    "## **Predictive Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-pittsburgh",
   "metadata": {},
   "source": [
    "Now that you have evaluated your model, the next step is to use it to predict an outcome. You use your model to predict the taxifare amount. The `ML.PREDICT` function is used to predict results using your model `feat_eng.final_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-escape",
   "metadata": {},
   "source": [
    "Since this is a regression model (predicting a continuous numerical value), the best way to see how it performed is to evaluate the difference between the value predicted by the model and the baseline score. We can do this with an `ML.PREDICT` query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-tribute",
   "metadata": {},
   "source": [
    "Apply the `ML.PREDICT` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "# Use `ML.PREDICT` function to predict outcomes using the model\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    ML.PREDICT(MODEL feat_eng.final_model,\n",
    "              (SELECT\n",
    "               -73.982683 AS pickuplon,\n",
    "               40.742104 AS pickuplat,\n",
    "               -73.983766 AS dropofflon,\n",
    "               40.755174 AS dropofflat,\n",
    "               3.0 AS passengers,\n",
    "               TIMESTAMP(\"2019-06-03 04:21:29.769443 UTC\") AS pickup_datetime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
