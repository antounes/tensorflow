{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attached-transportation",
   "metadata": {},
   "source": [
    "# **Introduction to Tensors and Variables**\n",
    "\n",
    "**Learning objectives**\n",
    "\n",
    "1. Understand basic and advanced `tensor` concepts\n",
    "2. Understand single-axis and multi-axis indexing\n",
    "3. Create `tensors` and `Variables`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-portland",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "In this notebook, we look at tensors, which are multi-dimensional arrays with a uniform type (called a `dtype`). Tensors are (kind of) like `np.arrays`. All tensors are immutable like Python numbers and strings: you can never update the contents of a tensor, only create a new one.\n",
    "\n",
    "We also look at variables, a `tf.Variable` represents a tensor whose value can be changed by running operations (ops) on it. Specific ops allow you to read and modify the value of this tensor. Higher level libraries like `tf.keras` use `tf.Variable` to store model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-scoop",
   "metadata": {},
   "source": [
    "## **Load necessary libraries**\n",
    "\n",
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "introductory-journalism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow version:\", tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-glance",
   "metadata": {},
   "source": [
    "## **Basic and advanced tensor concepts**\n",
    "\n",
    "### **Basics**\n",
    "\n",
    "Let's create some basic tensors. \n",
    "\n",
    "#### **Tensor objects**\n",
    "A **scalar** is a rank-0 tensor. A scalar contains a single value, and no *axes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sorted-czech",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A scalar tensor contains a single value and no axes\n",
    "rank_0_tensor = tf.constant(4)\n",
    "rank_0_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-initial",
   "metadata": {},
   "source": [
    "A **vector** is a rank-1 tensor. A vector is like a list of values, it has 1 axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "genuine-governor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([2., 3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A vector tensor has 1 axis\n",
    "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n",
    "rank_1_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-restoration",
   "metadata": {},
   "source": [
    "A **matrix** is a rank-2 tensor. It has 2 axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affiliated-bearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float16, numpy=\n",
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]], dtype=float16)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A matrix tensor has 2 axes\n",
    "# dtype can be specified at creation\n",
    "rank_2_tensor = tf.constant([[1, 2],\n",
    "                             [3, 4],\n",
    "                             [5, 6]], dtype=tf.float16)\n",
    "rank_2_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-pointer",
   "metadata": {},
   "source": [
    "<img src=\"img/tensors.png\" style=\"width:500px;height:220px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-report",
   "metadata": {},
   "source": [
    "Tensors may have more axes, here is a tensor with 3 axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sapphire-brake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 5), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9]],\n",
       "\n",
       "       [[10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19]],\n",
       "\n",
       "       [[20, 21, 22, 23, 24],\n",
       "        [25, 26, 27, 28, 29]]], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There can be an arbitrary number of axes\n",
    "rank_3_tensor = tf.constant([\n",
    "    [[0, 1, 2, 3, 4],\n",
    "     [5, 6, 7, 8, 9]],\n",
    "    [[10, 11, 12, 13, 14],\n",
    "     [15, 16, 17, 18, 19]],\n",
    "    [[20, 21, 22, 23, 24],\n",
    "     [25, 26, 27, 28, 29]]\n",
    "])\n",
    "\n",
    "rank_3_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-employer",
   "metadata": {},
   "source": [
    "Tensors with more than 2 axes can be visualised in many ways\n",
    "\n",
    "<img src=\"img/multi-tensors.png\" style=\"width:500px;height:220px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-touch",
   "metadata": {},
   "source": [
    "A tensor can be converted to a NumPy array either using `np.array` or the `tensor.numpy` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exceptional-stopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]], dtype=float16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rank_2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "assumed-indicator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]], dtype=float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-plain",
   "metadata": {},
   "source": [
    "Tensors often contain `float` and `int` types, but may have many other types, including:\n",
    "- complex numbers\n",
    "- strings\n",
    "\n",
    "The base `tf.Tensor` class requires tensors to be *rectangular* - that is, **along each axis, every element must be the same size**. However, some specialised types of tensors can handle different shapes:\n",
    "- ragged tensors\n",
    "- sparse tensors\n",
    "\n",
    "#### **Basic math**\n",
    "\n",
    "Basic math can be performed on tensors, including addition, element-wise multiplication, and matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accomplished-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "b = tf.constant([[1, 1],\n",
    "                 [1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-opening",
   "metadata": {},
   "source": [
    "**Addition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "electric-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.add(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pleasant-textbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-fortune",
   "metadata": {},
   "source": [
    "**Element-wise multiplication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "technological-montgomery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.multiply(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "logical-glory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(a * b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-addition",
   "metadata": {},
   "source": [
    "**Matrix multiplication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "continental-diagram",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.matmul(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cognitive-april",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(a @ b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-graphics",
   "metadata": {},
   "source": [
    "**Tensor ops**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "innocent-store",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2.6894143e-01, 7.3105860e-01],\n",
       "       [9.9987662e-01, 1.2339458e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.constant([[4.0, 5.0], \n",
    "                 [10.0, 1.0]])\n",
    "\n",
    "# Find the largest value\n",
    "tf.reduce_max(c)\n",
    "\n",
    "# Find the INDEX of the largest value\n",
    "tf.argmax(c)\n",
    "\n",
    "# Compute the softmax\n",
    "tf.nn.softmax(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-conversion",
   "metadata": {},
   "source": [
    "### **Tensor shapes**\n",
    "\n",
    "Tensors have shapes. Some vocabulary:\n",
    "- **Shape** - Tuple storing the length of each of the dimensions of a tensor\n",
    "- **Rank** - Number of tensor dimensions. A **scalar** is rank-0, a **vector** is rank-1, a **matrix** is rank-2\n",
    "- **Axis** or **Dimension** - Lowest structure level of a tensor\n",
    "- **Size** - Total number of the items in a tensor, its product shape vector\n",
    "\n",
    "Tensors and `tf.TensorShape` objects have convenient properties for accessing these.\n",
    "\n",
    "Note: although there may be references to *tensors of 2 dimensions*, a rank-2 tensor usually does not describe a 2D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "damaged-jacket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 4, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `tf.zeros` creates a tensor with all elements set to 0\n",
    "rank_4_tensor = tf.zeros([3, 2, 4, 5])\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-imagination",
   "metadata": {},
   "source": [
    "<img src=\"img/rank-4-tensor.png\" style=\"width:500px;height:400px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hazardous-lawyer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of every element: <dtype: 'float32'>\n",
      "Number of dimensions: 4\n",
      "Shape of tensor: (3, 2, 4, 5)\n",
      "Elements along axis 0 of tensor: 3\n",
      "Elements along the last axis of tensor: 5\n",
      "Total number of elements (3*2*4*5): 120\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of every element:\", rank_4_tensor.dtype)\n",
    "print(\"Number of dimensions:\", rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
    "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
    "print(\"Elements along the last axis of tensor:\", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elements (3*2*4*5):\", tf.size(rank_4_tensor).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-irish",
   "metadata": {},
   "source": [
    "While axes are often referred to by their indices, you should always keep track of the meaning of each. **Axes are ordered from global to local**: \n",
    "1. **batch** axis\n",
    "2. **spatial** axes\n",
    "3. **features** for each location\n",
    "\n",
    "This way feature vectors are contiguous regions of memory.\n",
    "\n",
    "<img src=\"img/tf-axes.png\" style=\"width:300px;height:200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-courtesy",
   "metadata": {},
   "source": [
    "## **Single-axis and multi-axis indexing**\n",
    "\n",
    "### **Single-axis indexing**\n",
    "\n",
    "TensorFlow follows standard Python and NumPy indexing rules:\n",
    "\n",
    "- indexes start at `0`\n",
    "- negative indices count backwards from the end\n",
    "- colons `:` are used for slicing as `start:stop:step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "internal-advertising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1,  2,  3,  5,  8, 13, 21, 34], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
    "rank_1_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-conclusion",
   "metadata": {},
   "source": [
    "Indexing with a scalar **removes the dimension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "front-garlic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First: 0\n",
      "Second: 1\n",
      "Last: 34\n"
     ]
    }
   ],
   "source": [
    "print(\"First:\", rank_1_tensor[0].numpy())\n",
    "print(\"Second:\", rank_1_tensor[1].numpy())\n",
    "print(\"Last:\", rank_1_tensor[-1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-value",
   "metadata": {},
   "source": [
    "Indexing with a slice `:` **keeps the dimension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "constitutional-minority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything: [ 0  1  1  2  3  5  8 13 21 34]\n",
      "Before 4:  [0 1 1 2]\n",
      "From 4 to the end: [ 3  5  8 13 21 34]\n",
      "From 2, before 7: [1 2 3 5 8]\n",
      "Every other item: [ 0  1  3  8 21]\n",
      "Reversed: [34 21 13  8  5  3  2  1  1  0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
    "print(\"Before 4: \", rank_1_tensor[:4].numpy())\n",
    "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
    "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
    "print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
    "print(\"Reversed:\", rank_1_tensor[::-1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-bandwidth",
   "metadata": {},
   "source": [
    "### **Multi-axis indexig**\n",
    "\n",
    "Higher rank tensors are indexed by passing multiple indices. The exact same rules as in the single-axis case apply to each axis independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "limiting-establishment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]], dtype=float16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-kuwait",
   "metadata": {},
   "source": [
    "Passing an integer for each index results in a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "liked-wrestling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull out a single value from a rank-2 tensor\n",
    "rank_2_tensor[1, 1].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-anxiety",
   "metadata": {},
   "source": [
    "Indexing can be performed using any combination of integers and slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "statewide-internship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second row: [3. 4.]\n",
      "Second column: [2. 4. 6.]\n",
      "Last row: [5. 6.]\n",
      "First item in the last column: 2.0\n",
      "Skip the first row:\n",
      "[[3. 4.]\n",
      " [5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# Get row and column tensors\n",
    "print(\"Second row:\", rank_2_tensor[1,:].numpy())\n",
    "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
    "print(\"Last row:\", rank_2_tensor[-1,:].numpy())\n",
    "print(\"First item in the last column:\", rank_2_tensor[0, -1].numpy())\n",
    "print(\"Skip the first row:\")\n",
    "print(rank_2_tensor[1:, :].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-maria",
   "metadata": {},
   "source": [
    "An example with a 3-axis tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "clean-appointment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 4,  9],\n",
       "       [14, 19],\n",
       "       [24, 29]], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get 3-axis tensor\n",
    "rank_3_tensor[:, :, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-authentication",
   "metadata": {},
   "source": [
    "<img src=\"img/rank-3-tensor.png\" style=\"width:400px;height:220px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-awareness",
   "metadata": {},
   "source": [
    "## **Manipulating shapes**\n",
    "\n",
    "Reshaping a tensor is of great utility. The `tf.reshape` operation is fast and cheap as the underlying data does not need to be duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "studied-messaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape returns a `tf.TensorShape` object that shows the size of each dimension\n",
    "var_x = tf.Variable(tf.constant([[1], [2], [3]]))\n",
    "var_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "filled-merchant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `tf.TensorShape` can be converted into a Python list\n",
    "var_x.shape.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-anatomy",
   "metadata": {},
   "source": [
    "A tensor can be reshaped into a new shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "lined-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = tf.reshape(var_x, [1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "appropriate-humidity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(var_x.shape)\n",
    "print(reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-flooring",
   "metadata": {},
   "source": [
    "The data maintains its layout in memory and a new tensor is created, with the requested shape, pointing to the same data. TensorFlow uses C-style \"row-major\" memory ordering, where incrementing the right-most index corresponds to a single step in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "becoming-judge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 5), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9]],\n",
       "\n",
       "       [[10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19]],\n",
       "\n",
       "       [[20, 21, 22, 23, 24],\n",
       "        [25, 26, 27, 28, 29]]], dtype=int32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_3_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-trinidad",
   "metadata": {},
   "source": [
    "A flattened tensor shows the order it is laid out in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "gentle-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30,), dtype=int32, numpy=\n",
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], dtype=int32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A `-1` passed in the `shape` argument says \"Whatever fits\"\n",
    "tf.reshape(rank_3_tensor, [-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-oliver",
   "metadata": {},
   "source": [
    "Typically, the only reasonable uses of `tf.reshape` are to combine or split adjacent axes (or add/remove `1`s). For this 3x2x5 tensor, reshaping to (3x2)x5 or 3x(2x5) are both reasonable things to do, as the slices do not mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "placed-still",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 5), dtype=int32, numpy=\n",
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24],\n",
       "       [25, 26, 27, 28, 29]], dtype=int32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(rank_3_tensor, [3*2, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "demographic-chester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 10), dtype=int32, numpy=\n",
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]], dtype=int32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(rank_3_tensor, [3, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-tenant",
   "metadata": {},
   "source": [
    "<img src=\"img/good-reshapes.png\" style=\"width:600px;height:200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-webcam",
   "metadata": {},
   "source": [
    "Reshaping will succeed for any new shape with the same total number of elements. It won't do anything useful if the order of the axes are not respected.\n",
    "\n",
    "Swapping axes in `tf.reshape` does not work, it requires `tf.transpose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "protected-animation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]\n",
      "  [10 11 12 13 14]]\n",
      "\n",
      " [[15 16 17 18 19]\n",
      "  [20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4  5]\n",
      " [ 6  7  8  9 10 11]\n",
      " [12 13 14 15 16 17]\n",
      " [18 19 20 21 22 23]\n",
      " [24 25 26 27 28 29]], shape=(5, 6), dtype=int32) \n",
      "\n",
      "Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]\n"
     ]
    }
   ],
   "source": [
    "# Bad reshaping examples\n",
    "\n",
    "print(tf.reshape(rank_3_tensor, [2, 3, 5]), \"\\n\")\n",
    "\n",
    "# This is a mess\n",
    "print(tf.reshape(rank_3_tensor, [5, 6]), \"\\n\")\n",
    "\n",
    "# This doesn't work at all\n",
    "try:\n",
    "    tf.reshape(rank_3_tensor, [7, -1])\n",
    "except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-opportunity",
   "metadata": {},
   "source": [
    "<img src=\"img/bad-reshapes.png\" style=\"width:600px;height:200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-collapse",
   "metadata": {},
   "source": [
    "## **More on `dtypes`**\n",
    "\n",
    "To inspect a `tf.Tensor` data type use `Tensor.dtype` property. \n",
    "\n",
    "When creating a `tf.Tensor` from a Python object, data type may optionally be specified. If not, TensorFlow selects a data type that can represent the data. TensorFlow converts Python integers to `tf.int32` and Python floating point numbers to `tf.float32`. Otherwise TensorFlow uses the same rules NumPy uses when converting to arrays.\n",
    "\n",
    "Casting from type to type is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "brave-disorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2.2 3.3 4.4], shape=(3,), dtype=float64)\n",
      "tf.Tensor([2.2 3.3 4.4], shape=(3,), dtype=float16)\n",
      "tf.Tensor([2 3 4], shape=(3,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "# `tf.cast` casts a tensor to a new type\n",
    "f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)\n",
    "print(f64_tensor)\n",
    "f16_tensor = tf.cast(f64_tensor, dtype=tf.float16)\n",
    "print(f16_tensor)\n",
    "# Now let's cast to uint8 and lose the decimal precision\n",
    "u8_tensor = tf.cast(f16_tensor, dtype=tf.uint8)\n",
    "print(u8_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-austin",
   "metadata": {},
   "source": [
    "## **Broadcasting**\n",
    "\n",
    "Broadcasting is a concept borrowed from the equivalent feature un NumPy. In short, under certain conditions, **smaller tensors are \"stretched\" automatically to fit larger tensors when running combined operations on them**.\n",
    "\n",
    "The simplest and most common case is the multiplication or addition of a tensor and a scalar. In that case, the scalar is broadcast to be the same shape as the other argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "forward-pattern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 2, 3])\n",
    "y = tf.constant(2)\n",
    "z = tf.constant([2, 2, 2])\n",
    "\n",
    "print(tf.multiply(x, 2))\n",
    "print(x * y)\n",
    "print(x * z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-force",
   "metadata": {},
   "source": [
    "Likewise, 1-sized dimensions can be stretched out to match the other arguments. Both arguments can be stretched in the same computation. In the following case, a 3x1 matrix is element-wise multiplied by a 1x4 matrix to produce a 3x4 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "statewide-celebrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32) \n",
      "\n",
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.reshape(x, [3, 1])\n",
    "y = tf.range(1, 5)\n",
    "print(x, \"\\n\")\n",
    "print(y, \"\\n\")\n",
    "print(tf.multiply(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-theory",
   "metadata": {},
   "source": [
    "<img src=\"img/broadcast.png\" style=\"width:400px;height:250px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-short",
   "metadata": {},
   "source": [
    "The same operation is done without broadcasting in the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "technical-apple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x_stretch = tf.constant([[1, 1, 1, 1],\n",
    "                         [2, 2, 2, 2],\n",
    "                         [3, 3, 3, 3]])\n",
    "y_stretch = tf.constant([[1, 2, 3, 4],\n",
    "                         [1, 2, 3, 4],\n",
    "                         [1, 2, 3, 4]])\n",
    "\n",
    "print(x_stretch * y_stretch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-decade",
   "metadata": {},
   "source": [
    "Most of the time, broadcasting is both time and memory efficient, as the broadcast operation never materialises the expanded tensors in memory. Broadcasting can be looked at using `tf.broadcast_to`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "endangered-culture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [1, 2, 3],\n",
       "       [1, 2, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-stamp",
   "metadata": {},
   "source": [
    "Unlike mathematical ops, for example, `tf.broadcast_to` does nothing special to save memory. Here, the tensor is materialised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-projector",
   "metadata": {},
   "source": [
    "## **`tf.convert_to_tensor`**\n",
    "\n",
    "Most ops, like `tf.matmul` and `tf.reshape` take arguments of class `tf.Tensor`. However, Python objects shaped like tensors are also frequently passed. Most, but not all, ops call `convert_to_tensor` on non-tensor arguments. There is a registry of conversions, and most object classes like NumPy `ndarray`, `TensorShape`, `list` and `tf.Variable` will convert automatically.\n",
    "\n",
    "## **Ragged tensors**\n",
    "\n",
    "A tensor with variable numbers of elements along some axis is called **ragged**. Use `tf.ragged.RaggedTensor` for ragged data.\n",
    "\n",
    "For example, this cannot be represented as a regular tensor:\n",
    "\n",
    "<img src=\"img/ragged-tensor.png\" style=\"width:300px;height:220px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pressed-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragged_list = [\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eastern-outside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't convert non-rectangular Python sequence to Tensor.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tensor = tf.constant(ragged_list)\n",
    "except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-litigation",
   "metadata": {},
   "source": [
    "Instead create a `tf.RaggedTensor` using `tf.ragged.constant` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "heated-paris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragged_tensor = tf.ragged.constant(ragged_list)\n",
    "ragged_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "optional-flight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, None])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragged_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-creature",
   "metadata": {},
   "source": [
    "## **String tensors**\n",
    "\n",
    "`tf.string` is a `dtype`, which is to say we can represent data as strings (variable-length byte in arrays) in tensors.\n",
    "\n",
    "**Strings are atomic and cannot be indexed in a Pythonic way**. The length of the string is not one of the dimensions of the tensor. Here is a scalar string tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "rental-generator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Foo bar'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors can be strings, too\n",
    "# Here is a scalar string\n",
    "scalar_string_tensor = tf.constant(\"Foo bar\")\n",
    "scalar_string_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-heart",
   "metadata": {},
   "source": [
    "And a vector of strings\n",
    "\n",
    "<img src=\"img/string-vector-tensor.png\" style=\"width:300px;height:200px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "understanding-quebec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Foo bar', b'Gray big wolf', b'Lazy dog'], dtype=object)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to have two string tensors of different lengths, this is OK\n",
    "tensor_of_strings = tf.constant([\"Foo bar\",\n",
    "                                 \"Gray big wolf\",\n",
    "                                 \"Lazy dog\"])\n",
    "# Note that the shape is (2,), indicating that it is `2 x unknown`\n",
    "tensor_of_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-eligibility",
   "metadata": {},
   "source": [
    "In the above printout the `b` prefix indicates that `tf.string` dtype is not a unicode string, but a byte-string.\n",
    "\n",
    "If you pass unicode characters they are utf8-encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "variable-frontier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xf0\\x9f\\xa5\\xb3\\xf0\\x9f\\x91\\x8d'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"ü•≥üëç\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-fence",
   "metadata": {},
   "source": [
    "Some basic functions with strings can be found in `tf.strings`, including `tf.strings.split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "statutory-arrival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'Foo', b'bar'], dtype=object)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use split to split a string into a set of tensors\n",
    "tf.strings.split(scalar_string_tensor, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "statewide-maldives",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'Foo', b'bar'], [b'Gray', b'big', b'wolf'], [b'Lazy', b'dog']]>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ...but it turns into a `tf.RaggedTensor` if we split up a tensor of strings,\n",
    "# as each string might be split into a different number of parts\n",
    "tf.strings.split(tensor_of_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-modern",
   "metadata": {},
   "source": [
    "<img src=\"img/ragged-string-tensor.png\" style=\"width:350px;height:220px;\">\n",
    "    \n",
    "\n",
    "And `tf.strings.to_number`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "powerful-coordinate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([  1.,  10., 100.], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `tf.strings.to_number` converts each string in the input tensor to the specified numeric type\n",
    "text = tf.constant(\"1 10 100\")\n",
    "tf.strings.to_number(tf.strings.split(text, \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-egyptian",
   "metadata": {},
   "source": [
    "Altough you can't use `tf.cast` to turn a string tensor into numbers, you can convert it into bytes, and then into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dangerous-capital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byte strings: tf.Tensor([b'D' b'u' b'c' b'k'], shape=(4,), dtype=string)\n",
      "Bytes: tf.Tensor([ 68 117  99 107], shape=(4,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "# Split string elements of input into bytes using `tf.strings.bytes_split`\n",
    "byte_strings = tf.strings.bytes_split(tf.constant(\"Duck\"))\n",
    "# `tf.io.decode_raw` reinterprets the bytes of a string as a vector of numbers\n",
    "byte_ints = tf.io.decode_raw(tf.constant(\"Duck\"), tf.uint8)\n",
    "print(\"Byte strings:\", byte_strings)\n",
    "print(\"Bytes:\", byte_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "unknown-behavior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unicode bytes: tf.Tensor(b'\\xe3\\x82\\xa2\\xe3\\x83\\x92\\xe3\\x83\\xab \\xf0\\x9f\\xa6\\x86', shape=(), dtype=string)\n",
      "\n",
      "Unicode chars: tf.Tensor([b'\\xe3\\x82\\xa2' b'\\xe3\\x83\\x92' b'\\xe3\\x83\\xab' b' ' b'\\xf0\\x9f\\xa6\\x86'], shape=(5,), dtype=string)\n",
      "\n",
      "Unicode values: tf.Tensor([ 12450  12498  12523     32 129414], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Or split it up as unicode and then decode it\n",
    "unicode_bytes = tf.constant(\"„Ç¢„Éí„É´ ü¶Ü\")\n",
    "# `tf.strings.unicode_split` splits each string in input into a sequence of Unicode code points\n",
    "unicode_char_bytes = tf.strings.unicode_split(unicode_bytes, \"UTF-8\")\n",
    "# `tf.strings.unicode_decode` decodes each string in input into a sequence of Unicode code points\n",
    "unicode_values = tf.strings.unicode_decode(unicode_bytes, \"UTF-8\")\n",
    "\n",
    "print(\"\\nUnicode bytes:\", unicode_bytes)\n",
    "print(\"\\nUnicode chars:\", unicode_char_bytes)\n",
    "print(\"\\nUnicode values:\", unicode_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-liquid",
   "metadata": {},
   "source": [
    "The `tf.string` dtype is used for all raw bytes data in TensorFlow. The `tf.io` module contains functions for **converting data to and from bytes**, including images and parsing csv.\n",
    "\n",
    "## **Sparse tensors**\n",
    "\n",
    "Sometimes, your data is sparse, like a very wide embedding space. TensorFlow supports `tf.sparse.SparseTensor` and related ops to store sparse data efficiently.\n",
    "\n",
    "<img src=\"img/sparse-tensor.png\" style=\"width:250px;height:200px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "determined-prospect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 0 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 0]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Sparse tensors store values by index in a memory-efficient manner\n",
    "sparse_tensor = tf.sparse.SparseTensor(indices=[[0,0], [1, 2]],\n",
    "                                       values=[1, 2],\n",
    "                                       dense_shape=[3, 4])\n",
    "print(sparse_tensor, \"\\n\")\n",
    "\n",
    "# We can convert sparse tensors to dense\n",
    "print(tf.sparse.to_dense(sparse_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-senegal",
   "metadata": {},
   "source": [
    "## **Introduction to variables**\n",
    "\n",
    "Variables are created and tracked via the `tf.Variable` class. A `tf.Variable` represents a **tensor whose value can be changed by running ops on it**.\n",
    "\n",
    "A TensorFlow **variable** is the recommended way to represent shared, persistent state your program manipulates. This guide covers how to create, update, and manage instances of `tf.Variable` in TensorFlow. Specific ops allow to read and modify the value of a `tf.Variable` tensor. Higher level libraries like `tf.keras` use `tf.Variable` to store model parameters.\n",
    "\n",
    "### **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "living-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-actress",
   "metadata": {},
   "source": [
    "### **Create a variable**\n",
    "\n",
    "To create a variable, provide an initial value. The `tf.Variable` will have the same `dtype` as the initialisation value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "visible-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set an initial value\n",
    "my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "# `tf.Variable` will have the same `dtype`\n",
    "my_variable = tf.Variable(my_tensor)\n",
    "\n",
    "# Variables can be all kinds of types, just like tensors\n",
    "bool_variable = tf.Variable([False, False, False, True])\n",
    "complex_variable = tf.Variable([5 + 4j, 6 + 1j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-blogger",
   "metadata": {},
   "source": [
    "A variable looks like and acts like a tensor, and, in fact, is a data structure backed by `tf.Tensor`. Like tensors, they have a `dtype` and a shape, and can be exported to NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "extraordinary-compensation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2, 2)\n",
      "dtype: <dtype: 'float32'>\n",
      "As NumPy: <bound method BaseResourceVariable.numpy of <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>>\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\", my_variable.shape)\n",
    "print(\"dtype:\", my_variable.dtype)\n",
    "print(\"As NumPy:\", my_variable.numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-tooth",
   "metadata": {},
   "source": [
    "Most tensor operations work on variables as expected, altough variables cannot be reshaped in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "south-enemy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A variable: <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>\n",
      "\n",
      "Viewed as a tensor: tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n",
      "\n",
      "Index of highest value: tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "\n",
      "Copying and reshaping: tf.Tensor([[1. 2. 3. 4.]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"A variable:\", my_variable)\n",
    "print(\"\\nViewed as a tensor:\", tf.convert_to_tensor(my_variable))\n",
    "print(\"\\nIndex of highest value:\", tf.argmax(my_variable))\n",
    "\n",
    "# This creates a new tensor; it does not reshape the initial variable\n",
    "print(\"\\nCopying and reshaping:\", tf.reshape(my_variable, ([1, 4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-thanksgiving",
   "metadata": {},
   "source": [
    "As noted above, variables are backed by tensors. You can reassign the tensor using `tf.Variable.assign`. Calling `assign` does not (usually) allocate a new tensor; instead, the existing tensor memory is reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "retained-ozone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot assign to variable Variable:0 due to variable shape (2,) and value shape (3,) are incompatible\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([2.0, 3.0])\n",
    "# This will keep the same `dtype`, `float32`\n",
    "a.assign([1, 2])\n",
    "# Not allowed as it resizes the variable\n",
    "try:\n",
    "    a.assign([1.0, 2.0, 3.0])\n",
    "except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-crack",
   "metadata": {},
   "source": [
    "If you use a variable like a tensor in operations, you will usually operate on the backing tensor. Creating new variables from existing variables duplicates the backing tensors. Two variables will not share the same memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "lyric-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 6.]\n",
      "[2. 3.]\n",
      "[7. 9.]\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([2.0, 3.0])\n",
    "# Create `b` based on thea value of `a`\n",
    "b = tf.Variable(a)\n",
    "a.assign([5, 6])\n",
    "\n",
    "# `a` and `b` are different\n",
    "print(a.numpy())\n",
    "print(b.numpy())\n",
    "\n",
    "# There are other versions of assign\n",
    "print(a.assign_add([2, 3]).numpy())\n",
    "print(a.assign_sub([7, 9]).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-father",
   "metadata": {},
   "source": [
    "### **Lifecyles, naming and watching**\n",
    "\n",
    "In Python-based TensorFlow, `tf.Variable` instances have the same lifecycle as other Python objects. When there are no references to a variable it is automatically deallocated.\n",
    "\n",
    "Variables can also be named which can help you track and debug them. You can give two variables the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "undefined-romance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
       "array([[False, False],\n",
       "       [False, False]])>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create `a` and `b`; they have the same name but are backed by different tensors\n",
    "a = tf.Variable(my_tensor, name=\"Mark\")\n",
    "# A new variable with the same name but different value\n",
    "# Note that the scalar added is broadcast\n",
    "b = tf.Variable(my_tensor + 1, name=\"Mark\")\n",
    "\n",
    "# These are element-wise unequal, despite having the same name\n",
    "a == b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-adelaide",
   "metadata": {},
   "source": [
    "Variable names are preserved when saving and loading models. By default, variables in models will acquire unique variable names automatically, so you don't need to assign them yourself unless you want to.\n",
    "\n",
    "Altough variables are important for differentiation, some variables will not need to be differentiated. You can turn off gradients for a variable by setting `trainable` to false at creation. An example of a variable that would not need gradients is a training step counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "palestinian-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can turn off gradients for a variable by setting trainable to false at creation\n",
    "step_counter = tf.Variable(1, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-thinking",
   "metadata": {},
   "source": [
    "### **Placing variables and tensors**\n",
    "\n",
    "For better performance, TensorFlow will attempt to place tensors and variables on the fastest device compatible with its `dtype`. This means most variables are placed on **a GPU** if one is available.\n",
    "\n",
    "However, we can override this. In this snippet, we can place a float tensor and a variable for the CPU even if a GPU is available. By turning on device placement logging, we can see where the variable is placed.\n",
    "\n",
    "Note: Although manual placement works, using distribution strategies can be a more convenient and scalable way to optimise your computation.\n",
    "\n",
    "If you run this notebook on different backends with and without a GPU you will see different logging. *Note that logging device placement must be turned on at the start of the session*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "intended-october",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[22., 28.],\n",
       "       [49., 64.]], dtype=float32)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you would like a particular operation to run on a device of your choice instead of what's \n",
    "# automatically selected for you, you can use `tf.device` to create a device context\n",
    "\n",
    "with tf.device(\"CPU:0\"):\n",
    "    # Create some tensors\n",
    "    a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "    \n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-joyce",
   "metadata": {},
   "source": [
    "It is possible to set the location of a variable or tensor on one device and do the computation on another device. This will introduce delay, as data needs to be copied between the devices.\n",
    "\n",
    "You might do this, however, if you had multiple GPU workers but only want one copy of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "integral-mayor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [ 4., 10., 18.]], dtype=float32)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.Variable([[1.0, 2.0, 3.0]])\n",
    "    \n",
    "with tf.device(\"GPU:0\"):\n",
    "    # Element-wise multiply\n",
    "    k = a * b\n",
    "\n",
    "k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
