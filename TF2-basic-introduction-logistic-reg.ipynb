{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wrong-analyst",
   "metadata": {},
   "source": [
    "# **Basic introduction to Logistic Regression in TensorFlow 2.0**\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "1. Build a logistic regression model\n",
    "2. Train the model on example data\n",
    "3. Use the model to make predictions about unknown data\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "This notebook walks through a classification problem. The goal is to *categorise* Iris flowers by species. TensorFlow is used for:\n",
    "- getting familiar with default eager execution environment\n",
    "- importing data with the Datasets API\n",
    "- building models and layers with the Keras API\n",
    "\n",
    "### **Configure imports**\n",
    "\n",
    "Import TensorFlow and the other required Python modules. By default, TensorFlow uses eager execution to evaluate operations immediately, returning concrete values instead of creating a computational graph to be executed (which would be lazy evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "advised-collins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.4.1\n",
      "Eager execution mode: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution mode: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-certification",
   "metadata": {},
   "source": [
    "## **The Iris classification problem**\n",
    "\n",
    "Imagine you are a botanist seeking an automated way to categorise each Iris flower you find. ML provides many algorithms to classify flowers statistically. For instance, a sophisticated ML program could classify flowers based on photographs. Our ambitions are more modest here -- we are going to classify Iris flowers based on the length and width measurements of their sepals and petals.\n",
    "\n",
    "The Iris genus entails about 300 species, but our program will only classify the following three:\n",
    "- Iris setosa\n",
    "- Iris virginica\n",
    "- Iris versicolor\n",
    "Fortunately, someone has already created a data set of 120 Iris flowers with the sepal and petal measurements. This is a classic data set that is popular for basic ML classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-liberal",
   "metadata": {},
   "source": [
    "### **Import and parse the training data set**\n",
    "Download the data set file and convert it into a structure to be fed into TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-canadian",
   "metadata": {},
   "source": [
    "#### **Download the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "commercial-overall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local copy of the data set file: /home/antounes/.keras/datasets/iris_training.csv\n"
     ]
    }
   ],
   "source": [
    "train_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "# tf.keras.utils.get_file returns an object file path named fname of the downloaded file from origin\n",
    "train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_url),\n",
    "                                           origin=train_url)\n",
    "print(\"Local copy of the data set file: {}\".format(train_dataset_fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-corrections",
   "metadata": {},
   "source": [
    "#### **Inspect the data**\n",
    "This data set, `iris_training.csv` is a plain text file that stores tabular data formatted as comma-separated values (CSV). Let's take a peek at the first five entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gentle-parking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120,4,setosa,versicolor,virginica\n",
      "6.4,2.8,5.6,2.2,2\n",
      "5.0,2.3,3.3,1.0,1\n",
      "4.9,2.5,4.5,1.7,2\n",
      "4.9,3.1,1.5,0.1,0\n"
     ]
    }
   ],
   "source": [
    "!head -n5 {train_dataset_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-interference",
   "metadata": {},
   "source": [
    "Note the following:\n",
    "1. The first line is a header containing information about the data set:\n",
    "- there are 120 total examples. Each example has four *features* and one of three possible *label names*\n",
    "2. Subsequent rows are data records, one example per line:\n",
    "- the first 4 fields are the *features*: here float numbers representing flower measurements\n",
    "- the last columnis the *label*: here an integer value corresponding to a flower name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ruled-employer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "Label: species\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
    "\n",
    "feature_names = column_names[:-1]\n",
    "label_name = column_names[-1]\n",
    "\n",
    "print(\"Features: {}\".format(feature_names))\n",
    "print(\"Label: {}\".format(label_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-binding",
   "metadata": {},
   "source": [
    "Each label is associated with a string name (e.g. `setosa`), but ML typically relies on *numeric values*. The label numbers are mapped to a named representation, such as:\n",
    "\n",
    "-`0`: Iris setosa\n",
    "-`1`: Iris versicolor\n",
    "-`2`: Iris virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "soviet-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Iris setosa\", \"Iris versicolor\", \"Iris virginica\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-duplicate",
   "metadata": {},
   "source": [
    "#### **Create a tf.data.Dataset**\n",
    "\n",
    "TensorFlow Dataset API handles many common cases for loading data into a model. This is a high-level API for reading data and transforming it into a form used for training.\n",
    "\n",
    "Since the dataset is a CSV-formatted text file, we'll use `tf.data.experimental.make_csv_dataset` to parse the data into a suitable format. This function generates new data for training models, the default behaviour is to shuffle the data `(shuffle=True, shuffle_buffer_size=10000)` and repeat the dataset forever `(num_epochs=None)`; the `batch_size` parameter is also set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "global-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    train_dataset_fp,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name=label_name,\n",
    "    num_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-platinum",
   "metadata": {},
   "source": [
    "The `make_csv_dataset` function returs a `tf.data.Dataset` of `(features, label)` pairs, where `features` is a `dict`: `{\"feature_name\": value}`.\n",
    "The `tf.data.Dataset` objects are iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "determined-airline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('sepal_length', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([5.4, 4.8, 6.3, 4.9, 5.1, 6.5, 7.2, 6.3, 6.9, 6.1, 6. , 4.9, 5.4,\n",
      "       5.6, 5.1, 4.6, 4.4, 4.9, 6.4, 5.4, 6.3, 6.7, 5.8, 6.9, 4.9, 4.8,\n",
      "       5.3, 4.8, 6.9, 4.4, 5.2, 6.1], dtype=float32)>), ('sepal_width', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([3. , 3. , 2.5, 3.1, 3.8, 3.2, 3.6, 3.3, 3.2, 3. , 2.9, 3.1, 3.9,\n",
      "       2.7, 3.7, 3.6, 3. , 3. , 2.8, 3.4, 2.3, 3.3, 4. , 3.1, 3.1, 3.4,\n",
      "       3.7, 3. , 3.1, 2.9, 2.7, 2.9], dtype=float32)>), ('petal_length', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([4.5, 1.4, 5. , 1.5, 1.9, 5.1, 6.1, 6. , 5.7, 4.9, 4.5, 1.5, 1.3,\n",
      "       4.2, 1.5, 1. , 1.3, 1.4, 5.6, 1.5, 4.4, 5.7, 1.2, 4.9, 1.5, 1.6,\n",
      "       1.5, 1.4, 5.1, 1.4, 3.9, 4.7], dtype=float32)>), ('petal_width', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([1.5, 0.3, 1.9, 0.1, 0.4, 2. , 2.5, 2.5, 2.3, 1.8, 1.5, 0.1, 0.4,\n",
      "       1.3, 0.4, 0.2, 0.2, 0.2, 2.1, 0.4, 1.3, 2.1, 0.2, 1.5, 0.1, 0.2,\n",
      "       0.2, 0.1, 2.3, 0.2, 1.4, 1.4], dtype=float32)>)])\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(train_dataset))\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-batch",
   "metadata": {},
   "source": [
    "Like-features are grouped together, or *batched*. Each example row's fields are appended to the corresponding feature array. The `batch_size` parameter controls the number of examples stored in the feature arrays. Let's have a look at some plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "employed-michigan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(\n",
    "    features[\"petal_length\"],\n",
    "    features[\"sepal_length\"],\n",
    "    c=labels,\n",
    "    cmap=\"viridis\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Petal length\")\n",
    "plt.ylabel(\"Sepal length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-planning",
   "metadata": {},
   "source": [
    "To simplify the model building step, create a function to repackage the features `dict` into a single array with shape: `(batch_size, num_features)`. This function uses the `tf.stack` method which takes values from a list of tensors and creates a combined tensor at the specified dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "continuing-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_features_vector(features, labels):\n",
    "    \"\"\"Pack the features into a single array\"\"\"\n",
    "    features = tf.stack(list(features.values()), axis=1)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-sperm",
   "metadata": {},
   "source": [
    "Then use the `tf.data.Dataset` `map` method to pack the `features` of each `(features, label)` pair into the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "satisfactory-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(pack_features_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-tongue",
   "metadata": {},
   "source": [
    "The features element of the `tf.data.Dataset` are now arrays with shape `(batch_size, num_features)`. Let's have a look at a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "clean-membership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[6.4 3.2 4.5 1.5]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.  3.  4.8 1.8]\n",
      " [7.2 3.  5.8 1.6]], shape=(5, 4), dtype=float32) tf.Tensor([1 2 2 2 2], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(train_dataset))\n",
    "print(features[:5], labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-apparatus",
   "metadata": {},
   "source": [
    "### **Select the type of model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-magnitude",
   "metadata": {},
   "source": [
    "#### **Why model ?**\n",
    "\n",
    "A *model* is a relationship between the `features` and the `label`. For the Iris classification problem, the model defines the relationship between the sepal and petal measurements and the predicted Iris species. Some simple models can be described with a few lines of algebra, but complex machine learning models have a large number of parameters that are difficult to summarize.\n",
    "\n",
    "Could you determine the relationship between the four features and the Iris species *without* using machine learning ? That is, could you use traditional programming techniques (e.g. a lot of conditional statements) to create a model ? Perhaps - if you analysed the dataset long enough to determine the relationships between petal and sepal measurement to a particular species. And this becomes difficult - maybe impossible - on more complicated datasets. A good machine learning approach *determines the model for you*. If you feed enough representative examples into the right ML model type, it will figure out the relationships for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-pepper",
   "metadata": {},
   "source": [
    "#### **Select the model**\n",
    "\n",
    "We need to select the kind of model to train. There are many types of models and picking a good one takes experience. This tutorial uses a neural network to solve the Iris classification problem. *Neural networks* can find complex relationships between the features and the label. \n",
    "\n",
    "It's a highly-structured graph, organised into one or more *hidden layers*. Each hidden layer consists of one or more *neurons*. There are several categories of neural networks and this program uses a *dense*, or *fully-connected* neural network: neurons in one layer receive input connections from *every* neuron in the previous layer. Below example of a dense neural network consisting of an input layer, two hidden layers and an output layer.\n",
    "\n",
    "<img src=\"fully-connected-net.png\"> \n",
    "\n",
    "When this model is trained and fed an unlabeled example, it yields three predictions: the likelihood that this flower is the given Iris species. This prediction is called *inference*. For this example, the sum of the output prediction is `1.0`. Here, the model predicts that the fed unlabeled example flower is an *Iris versicolor* with $95~\\%$ probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-aluminum",
   "metadata": {},
   "source": [
    "#### **Create a model using `tf.keras.Sequential`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-science",
   "metadata": {},
   "source": [
    "The TensorFlow `tf.keras` API is the preferred way to created models and layers. This makes it easy to build models and experiment while `Keras` handles the complexity of connecting everything together.\n",
    "\n",
    "The `tf.keras.Sequential` model is a linear stack of layers. Its constructor takes a list of layers instances and an output layer. Here we'll use 2 `tf.keras.layers.Dense` layers with 10 nodes each and an output layer with 3 nodes representing our label predictions. \n",
    "\n",
    "The first layer's `input_shape` parameter corresponds to the number of features from the dataset, and is required. The `activation` parameter decides which *activation function* to use and determines the output shape of each node in the layer. These non-linearities are important - without them the model would be equivalent to a single layer. There are many `tf.keras.activations`, but `ReLU` is common for hidden layers.\n",
    "\n",
    "The ideal number of hidden layers and neurons depends on the problem and the dataset. Like many aspects of ML, picking the best shape of a neural network requires a mixture of knowledge and experimentation. As a rule of thumb, **increasing the number of hidden layers and neurons typically creates a more powerful model, thus requiring mode data to train efficiently** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "critical-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(3)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-bedroom",
   "metadata": {},
   "source": [
    "#### **Using the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-truth",
   "metadata": {},
   "source": [
    "Let's have a quick look at what this model does with a batch of `features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "outside-verse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[-1.2545208 ,  1.8786243 ,  0.25325692],\n",
       "       [-1.2109331 ,  1.8507948 ,  0.08853996],\n",
       "       [-1.1591718 ,  1.7769098 ,  0.02409589],\n",
       "       [-1.225023  ,  1.7955794 ,  0.10662377],\n",
       "       [-1.2517062 ,  2.2210875 ,  0.234689  ]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(features)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-nursing",
   "metadata": {},
   "source": [
    "Here each example returns a `logit` for each class. A **logit** is a vector of raw predictions generated by a classification model, and is generally passed on to a normalised function. If the model is solving a multi-class classification problem, logits are generally fed into the `softmax` function. **softmax** generates a vector of normalised probabilities with one value for each possible class.\n",
    "\n",
    "In addition, logit sometimes refers to the element-wise inverse of the *sigmoid function*.\n",
    "\n",
    "Logits must then be converted into probabilities for each class by using the `softmax` output function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "emerging-engineer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.03513368, 0.8061786 , 0.15868768],\n",
       "       [0.03841455, 0.8207054 , 0.14088014],\n",
       "       [0.04327712, 0.815422  , 0.14130093],\n",
       "       [0.03953989, 0.8107117 , 0.14974843],\n",
       "       [0.026562  , 0.856004  , 0.11743402]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-kansas",
   "metadata": {},
   "source": [
    "And taking the `tf.argmax` across classes gives us the predicted class index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "hazardous-ballet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "    Labels: [1 2 2 2 2 0 2 1 0 1 2 0 1 1 0 2 2 2 2 1 1 2 1 2 1 0 0 1 2 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction: {}\".format(tf.argmax(predictions, axis=1)))\n",
    "print(\"    Labels: {}\".format(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-spice",
   "metadata": {},
   "source": [
    "But the model hasn't been trained yet, so these aren't good predictions. Indeed, the model here predicts that all species are *Iris versicolor*..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-indian",
   "metadata": {},
   "source": [
    "### **Train the model**\n",
    "\n",
    "*Training* is the stage of ML when the model is gradually optimised, or the model *learns* the dataset. The goal is to learn enough about the structure of training dataset to make predictions about unseen data (i.e. to **generalise**). If the model learns *too much* about the training data set, then the predictions only work for the data it has seen and will not be generalisable. This problem is called **overfitting** - it's like memorising answers instead of learning how to solve a problem.\n",
    "\n",
    "The Iris classification problem is an example of *supervised machine learning*: the model is trained from examples that contain labels. In *unsupervised machine learning*, examples don't contain labels. Instead, the model typically finds patterns among the features.\n",
    "\n",
    "#### **Define the loss and gradient functions**\n",
    "\n",
    "Both training and evaluation stages need to calculate the model **loss**. This measures how off predictions of a model are from the true label. In other words, it accounts for how bad a model performs. The goal is to minimise this value, this being an optimisation problem.\n",
    "\n",
    "Loss is calculated using the `tf.keras.losses.SparseCategoricalCrossentropy` function which takes the model class probability predictions and the true label as inputs, and returns the average loss across the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "norman-glenn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss test: 1.8248038291931152\n"
     ]
    }
   ],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def loss(model, x, y, training):\n",
    "    #training is required only if layers behave differently between training and inference (e.g. Dropout)\n",
    "    y_hat = model(x, training=training)\n",
    "    \n",
    "    return loss_object(y_true=y, y_pred=y_hat)\n",
    "\n",
    "l = loss(model,features, labels, training=False)\n",
    "print(\"Loss test: {}\".format(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-masters",
   "metadata": {},
   "source": [
    "Gradients are calculated as vectors of partial derivatives of the model function. The gradient points in the direction of steepest ascent. They're stored within a *context*, using `tf.GradientTape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "uniform-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, training=True)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-reunion",
   "metadata": {},
   "source": [
    "#### **Create an optimiser**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-protest",
   "metadata": {},
   "source": [
    "An **optimiser** applies the computed gradients to the model variables to minimise the `loss` function. You can think of the loss function as a curved surface and the goal is to find its lowest point by walking around. The gradient points in the direction of the steepest ascent - so we'll travel to the opposite way and move down the hill. **By iteratively calculating the loss and gradient for each batch, we'll adjust the model during training**. Gradually, the best combination of weights and bias will be found to minimise loss. And the lower the loss, the better the model predictions. \n",
    "\n",
    "**Gradient descent** is an algorithm used for finding the optimal model configuration (i.e. parameters values) by minimising the model loss thanks to the computation of the gradients of loss with respect to the model parameters, conditioned on training data. Informally, gradient descent iteratively adjusts parameters gradually finding the best combination of weights and bias to minimise loss.\n",
    "\n",
    "<img src=\"gradients.gif\" width=500 height=500> \n",
    "\n",
    "TensorFlow has many optimisation algorithms available for training. Here we'll use `tf.keras.optimizers.SGD` that implements the *stochastic gradient descent* (SGD) algorithm. **Stochastic gradient descent** is a gradient descent algorithm in which the batch size is equal to $1$, relying on a single example chosen uniformly at random from a data set. The `learning_rate` sets the step size to take for each iteration down the hill. This is a *hyperparameter* that controls the training process itslef and is commonly adjusted to achieve better results.\n",
    "\n",
    "Let's build the optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "marine-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-cisco",
   "metadata": {},
   "source": [
    "Now let's use the optimiser to compute a single optimisation step and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "caroline-teacher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Initial Loss: 1.8248038291931152\n",
      "Step: 0,         Loss: 1.5501675605773926\n"
     ]
    }
   ],
   "source": [
    "loss_value, grads = grad(model, features, labels)\n",
    "\n",
    "print(\"Step: {}, Initial Loss: {}\".format(\n",
    "    optimizer.iterations.numpy(),\n",
    "    loss_value.numpy()))\n",
    "\n",
    "optimiser.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "print(\"Step: {},         Loss: {}\".format(\n",
    "    optimizer.iterations.numpy(),\n",
    "    loss(model, features, labels, training=True).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-shareware",
   "metadata": {},
   "source": [
    "#### **Training loop**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-clarity",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
