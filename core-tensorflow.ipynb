{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "israeli-upgrade",
   "metadata": {},
   "source": [
    "# **Getting started with TensorFlow**\n",
    "\n",
    "**Learning objectives**\n",
    "\n",
    "1. Practice defining and performing basic operations on tensors\n",
    "2. Use TensorFlow automatic differentiation capability\n",
    "3. Learn how to train a linear regression from scratch with TensorFlow\n",
    "\n",
    "In this notebook, we will start by reviewing the main operations on tensors in TensorFlow and understand how to manipulate TensorFlow Variables. We explain how these are compatible with Python built-in `list` and NumPy `array` objects.\n",
    "\n",
    "Then we will jump to the problem of training a linear regression from scratch with gradient descent. The first order of business will be to understand how to compute the gradients of a function (a loss function here) with respect to some of its arguments (the model weights here). The TensorFlow construct allowing us to do that is `tf.GradientTape`, which we will describe.\n",
    "\n",
    "At last we will create a simple training loop to learn the weights of a 1-dim linear regression using synthetic data generated from a linear model.\n",
    "\n",
    "As a bonus exercise, we will do the same for data generated from a non-linear model, forcing us to manual-engineer non-linear features to improve our linear model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "driven-crown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-celebrity",
   "metadata": {},
   "source": [
    "## **Operations on tensors**\n",
    "\n",
    "### **Variables and constants**\n",
    "\n",
    "Tensors in TensorFlow are either **constants** (`tf.constant`) or **variables** (`tf.Variable`). Constant values cannot be changed, while variable values can be.\n",
    "\n",
    "The main difference is that instances of `tf.Variable` have methods allowing us to change their values while tensors constructed with `tf.constant` don't have these methods, and therefore their values cannot be changed. When you want to change the value of a `tf.Variable` `x` use one of the following methods:\n",
    "\n",
    "- `x.assign(new_value)`\n",
    "- `x.assign_add(value_to_be_added)`\n",
    "- `x.assign_sub(value_to_be_subtracted)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "homeless-attention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 3, 4], dtype=int32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([2, 3, 4])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "likely-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(2.0, dtype=tf.float32, name=\"my_variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "phantom-perspective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'my_variable:0' shape=() dtype=float32, numpy=45.8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.assign(45.8)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "plain-agency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'my_variable:0' shape=() dtype=float32, numpy=49.8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.assign_add(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "manual-tradition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'my_variable:0' shape=() dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.assign_sub(49.8)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-schema",
   "metadata": {},
   "source": [
    "### **Point-wise operations**\n",
    "\n",
    "TensorFlow offers similar point-wise tensor operations as NumPy does:\n",
    "\n",
    "- `tf.add` allows to add the components of a tensor\n",
    "- `tf.multiply` allows to multiply the components of a tensor\n",
    "- `tf.subtract` allows to subtract the components of a tensor\n",
    "- `tf.math.*` contains the usual `math` operations to be applied on the components of a tensor\n",
    "\n",
    "Most of the standard arithmetic ops (`tf.add`, `tf.subtract`, etc.) are overloaded by the usual corresponding arithmetic symbols (`+`, `-`, `*`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "personalized-divorce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: tf.Tensor([ 8  2 10], shape=(3,), dtype=int32)\n",
      "d: tf.Tensor([ 8  2 10], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([5, 3, 8])\n",
    "b = tf.constant([3, -1, 2])\n",
    "c = tf.add(a, b)\n",
    "d = a + b\n",
    "\n",
    "print(\"c:\", c)\n",
    "print(\"d:\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dedicated-affiliation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: tf.Tensor([15 -3 16], shape=(3,), dtype=int32)\n",
      "d: tf.Tensor([15 -3 16], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([5, 3, 8])\n",
    "b = tf.constant([3, -1, 2])\n",
    "c = tf.multiply(a, b)\n",
    "d = a * b\n",
    "\n",
    "print(\"c:\", c)\n",
    "print(\"d:\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "heated-lease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: tf.Tensor([ 148.41316    20.085537 2980.958   ], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.math.exp expects floats so we need to explicitely give the type\n",
    "a = tf.constant([5, 3, 8], dtype=tf.float32)\n",
    "b = tf.math.exp(a)\n",
    "\n",
    "print(\"b:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-methodology",
   "metadata": {},
   "source": [
    "### **Point-wise operations**\n",
    "\n",
    "In addition to naive TensorFlow tensors, tensorflow operations can take native Python types and NumPy `array` operands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "freelance-glasgow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Native Python lists\n",
    "a_py = [1, 2]\n",
    "b_py = [3, 4]\n",
    "\n",
    "tf.add(a_py, b_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "danish-cancellation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([4, 6])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy arrays\n",
    "a_np = np.array([1, 2])\n",
    "b_np = np.array([3, 4])\n",
    "\n",
    "tf.add(a_np, b_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "environmental-sheriff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Native TensorFlow tensors\n",
    "a_tf = tf.constant([1, 2])\n",
    "b_tf = tf.constant([3, 4])\n",
    "\n",
    "tf.add(a_tf, b_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-waters",
   "metadata": {},
   "source": [
    "You can convert a native TensorFlow tensor to a NumPy array using `.numpy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "amazing-breathing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tf.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-amplifier",
   "metadata": {},
   "source": [
    "## **Linear Regression**\n",
    "\n",
    "Now let's use low level TensorFlow operations to implement linear regression.\n",
    "\n",
    "### **Toy Dataset**\n",
    "\n",
    "We'll model the following function\n",
    "\n",
    "$$\n",
    "y = 2x + 10\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "maritime-baghdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "Y: [10. 12. 14. 16. 18. 20. 22. 24. 26. 28.]\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant(range(10), dtype=tf.float32)\n",
    "Y = 2 * X + 10\n",
    "\n",
    "print(\"X: {}\".format(X))\n",
    "print(\"Y: {}\".format(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-sacrifice",
   "metadata": {},
   "source": [
    "Let's also create a test data set to evaluate our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "stylish-young",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: [10. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "Y_test: [30. 32. 34. 36. 38. 40. 42. 44. 46. 48.]\n"
     ]
    }
   ],
   "source": [
    "X_test = tf.constant(range(10, 20), dtype=tf.float32)\n",
    "Y_test = 2 * X_test + 10\n",
    "\n",
    "print(\"X_test: {}\".format(X_test))\n",
    "print(\"Y_test: {}\".format(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-islam",
   "metadata": {},
   "source": [
    "### **Loss function**\n",
    "\n",
    "The simplest model we can build is a model that for each value of `x` returns the sample mean of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "opened-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mean(X):\n",
    "    y_hat = [Y.numpy().mean()] * len(X)\n",
    "    return y_hat\n",
    "\n",
    "Y_hat = predict_mean(X_test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-station",
   "metadata": {},
   "source": [
    "Using *Mean Squared Error* as the error function, our loss is\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{m}\\sum_{i=1}^m(\\hat{Y}_i - Y_i)^2\n",
    "$$\n",
    "\n",
    "For our simple model the loss is then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "opened-cooling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.reduce_mean((Y_hat - Y)**2)\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-biotechnology",
   "metadata": {},
   "source": [
    "This very bad value for the MSE loss above will give us a baseline to compare how a more complex model is doing.\n",
    "\n",
    "Now, if $\\hat{Y}$ represents the vector containing our model predictions when we use a linear regression model, then we have:\n",
    "\n",
    "$$\n",
    "\\hat{Y} = w_0X + w_1\n",
    "$$\n",
    "\n",
    "we can write a loss function taking as arguments the coefficients (or parameters) of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "elect-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mse(X, Y, w0, w1):\n",
    "    Y_hat = w0 * X + w1\n",
    "    return tf.reduce_mean((Y_hat - Y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-technician",
   "metadata": {},
   "source": [
    "### **Gradient function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-virtue",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
